{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX Documentation\n",
    "\n",
    "The ONNX (Open Neural Network eXchange) model format is an open standard for representing machine learning algorithms as such it can be used for creating your model in any of the Machine Learning frameworks that have the ability to be converted to the ONNX format. Some of the available frameworks are: Tensorflow, Keras, PyTorch, scikit-learn, Apple Core ML, Spark ML, LightGBM, libsvm, XGBoost, among others.\n",
    "\n",
    "Additional Resources:\n",
    "- https://onnx.ai/supported-tools.html\n",
    "- https://github.com/onnx/onnx/blob/main/docs/PythonAPIOverview.md\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "* [Onnx Conversion](#1)\n",
    "    * [Different formats to ONNX](#1-1)\n",
    "        * [TensorFlow/Keras](#1-1-1)\n",
    "        * [PyTorch](#1-1-2)\n",
    "        * [Scikit-learn](#1-1-3)\n",
    "        * [XGBoost](#1-1-4)\n",
    "    * [Conversion Pitfalls](#1-2)\n",
    "* [Graph Modifications](#2)\n",
    "    * [Onnxruntime optimization](#2-0)\n",
    "    * [Remapping model inputs](#2-1)\n",
    "    * [Renaming model outputs](#2-2)\n",
    "    * [Merging graphs](#2-3)\n",
    "* [Time Series Data](#3)\n",
    "    * [Kshape](#3-1)\n",
    "    * [DTW](#3-2)\n",
    "    * [Resampling](#3-3)\n",
    "* [ONNX Prediction](#4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onnx Conversion <a class=\"anchor\" id=\"1\"></a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different formats to ONNX <a class=\"anchor\" id=\"1-1\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow/Keras to ONNX <a class=\"anchor\" id=\"1-1-1\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to convert a TensorFlow or a Keras model to ONNX is to  save the model in tensorflow's SavedModel format, as stated in the documentation (https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model)\n",
    "\n",
    "Additional Resource:\n",
    "- https://github.com/onnx/tensorflow-onnx\n",
    "- https://www.tensorflow.org/guide/saved_model\n",
    "- https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from acslibrary.onnx_utils.conversion import tensorflow_to_onnx\n",
    "\n",
    "# Example keras model\n",
    "tf_model = tf.keras.Sequential(\n",
    "  [\n",
    "    tf.keras.layers.Dense(5, input_shape=(3,)),\n",
    "    tf.keras.layers.Softmax(),\n",
    "  ]\n",
    ")\n",
    "\n",
    "# Save model in onnx format\n",
    "onnx_model_path = './models/tf_model.onnx'\n",
    "tensorflow_to_onnx(tf_model, save_onnx_filename=onnx_model_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch to ONNX <a class=\"anchor\" id=\"1-1-2\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch has native support (https://pytorch.org/docs/stable/onnx.html) for ONNX export and as such can be exported directly from code.\n",
    "\n",
    "Additional Resources:\n",
    "- https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from acslibrary.onnx_utils.conversion import pytorch_to_onnx\n",
    "\n",
    "# Define the PyTorch model to export\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(10, 5)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "torch_model = MyModel()\n",
    "\n",
    "# Define an example input to use for tracing the model\n",
    "example_input = torch.randn(1, 10)\n",
    "\n",
    "# Export the model to ONNX format\n",
    "save_onnx_filename = \"./models/pytorch_model.onnx\"\n",
    "pytorch_to_onnx(torch_model,\n",
    "                example_input,\n",
    "                save_onnx_filename,\n",
    "                export_params=True,             # store the trained parameter weights inside the model file\n",
    "                input_names = ['input'],        # the model's input names\n",
    "                output_names = ['output'],      # the model's output names\n",
    "                dynamic_axes={\n",
    "                    'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                    'output' : {0 : 'batch_size'},\n",
    "                })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SciKit-Learn to ONNX <a class=\"anchor\" id=\"1-1-3\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn_to_onnx` converts either an sklearn model or Pipeline to ONNX format, allowing to define initial_types or infer them from train data X. The function saves the model to *save_onnx_filename* if the parameter is declared, otherwise it returns the converted model.\n",
    "\n",
    "Additional Resources:\n",
    "- http://onnx.ai/sklearn-onnx/\n",
    "- https://github.com/onnx/sklearn-onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-25 14:08:25.452431: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ir_version: 8\n",
       "producer_name: \"skl2onnx\"\n",
       "producer_version: \"1.14.0\"\n",
       "domain: \"ai.onnx\"\n",
       "model_version: 0\n",
       "doc_string: \"\"\n",
       "graph {\n",
       "  node {\n",
       "    input: \"float_input\"\n",
       "    output: \"label\"\n",
       "    output: \"probabilities\"\n",
       "    name: \"TreeEnsembleClassifier\"\n",
       "    op_type: \"TreeEnsembleClassifier\"\n",
       "    attribute {\n",
       "      name: \"class_ids\"\n",
       "      ints: 0\n",
       "      ints: 0\n",
       "      type: INTS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"class_nodeids\"\n",
       "      ints: 1\n",
       "      ints: 2\n",
       "      type: INTS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"class_treeids\"\n",
       "      ints: 0\n",
       "      ints: 0\n",
       "      type: INTS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"class_weights\"\n",
       "      floats: 0.0\n",
       "      floats: 1.0\n",
       "      type: FLOATS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"classlabels_int64s\"\n",
       "      ints: 0\n",
       "      ints: 1\n",
       "      type: INTS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"nodes_falsenodeids\"\n",
       "      ints: 2\n",
       "      ints: 0\n",
       "      ints: 0\n",
       "      type: INTS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"nodes_featureids\"\n",
       "      ints: 0\n",
       "      ints: 0\n",
       "      ints: 0\n",
       "      type: INTS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"nodes_hitrates\"\n",
       "      floats: 1.0\n",
       "      floats: 1.0\n",
       "      floats: 1.0\n",
       "      type: FLOATS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"nodes_missing_value_tracks_true\"\n",
       "      ints: 0\n",
       "      ints: 0\n",
       "      ints: 0\n",
       "      type: INTS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"nodes_modes\"\n",
       "      strings: \"BRANCH_LEQ\"\n",
       "      strings: \"LEAF\"\n",
       "      strings: \"LEAF\"\n",
       "      type: STRINGS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"nodes_nodeids\"\n",
       "      ints: 0\n",
       "      ints: 1\n",
       "      ints: 2\n",
       "      type: INTS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"nodes_treeids\"\n",
       "      ints: 0\n",
       "      ints: 0\n",
       "      ints: 0\n",
       "      type: INTS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"nodes_truenodeids\"\n",
       "      ints: 1\n",
       "      ints: 0\n",
       "      ints: 0\n",
       "      type: INTS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"nodes_values\"\n",
       "      floats: 0.5\n",
       "      floats: 0.0\n",
       "      floats: 0.0\n",
       "      type: FLOATS\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"post_transform\"\n",
       "      s: \"NONE\"\n",
       "      type: STRING\n",
       "    }\n",
       "    domain: \"ai.onnx.ml\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"label\"\n",
       "    output: \"output_label\"\n",
       "    name: \"Cast\"\n",
       "    op_type: \"Cast\"\n",
       "    attribute {\n",
       "      name: \"to\"\n",
       "      i: 7\n",
       "      type: INT\n",
       "    }\n",
       "    domain: \"\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"probabilities\"\n",
       "    output: \"output_probability\"\n",
       "    name: \"ZipMap\"\n",
       "    op_type: \"ZipMap\"\n",
       "    attribute {\n",
       "      name: \"classlabels_int64s\"\n",
       "      ints: 0\n",
       "      ints: 1\n",
       "      type: INTS\n",
       "    }\n",
       "    domain: \"ai.onnx.ml\"\n",
       "  }\n",
       "  name: \"ONNX(DecisionTreeClassifier)\"\n",
       "  input {\n",
       "    name: \"float_input\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: 1\n",
       "        shape {\n",
       "          dim {\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 2\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  output {\n",
       "    name: \"output_label\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: 7\n",
       "        shape {\n",
       "          dim {\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  output {\n",
       "    name: \"output_probability\"\n",
       "    type {\n",
       "      sequence_type {\n",
       "        elem_type {\n",
       "          map_type {\n",
       "            key_type: 7\n",
       "            value_type {\n",
       "              tensor_type {\n",
       "                elem_type: 1\n",
       "              }\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "opset_import {\n",
       "  domain: \"\"\n",
       "  version: 9\n",
       "}\n",
       "opset_import {\n",
       "  domain: \"ai.onnx.ml\"\n",
       "  version: 1\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "from acslibrary.onnx_utils.conversion import sklearn_to_onnx\n",
    "\n",
    "# Example classification model (needs X_train and y_train)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "X_train = [[0, 0], [1, 1]]\n",
    "y_train = [0, 1]\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Define the input type and shape\n",
    "initial_type = [('float_input', FloatTensorType([None, 2]))]\n",
    "\n",
    "# Convert model to onnx\n",
    "save_onnx_filename = \"./models/sklearn_tree_model.onnx\"\n",
    "sklearn_to_onnx(clf, initial_types=initial_type, save_onnx_filename=save_onnx_filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost to ONNX <a class=\"anchor\" id=\"1-1-4\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework.\n",
    "\n",
    "Additional Resources:\n",
    "- https://xgboost.readthedocs.io/en/stable/index.html\n",
    "- https://onnx.ai/sklearn-onnx/auto_tutorial/plot_gexternal_xgboost.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import onnxruntime as ort\n",
    "\n",
    "from acslibrary.onnx_utils.conversion import xgboost_to_onnx\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data[:, :2]\n",
    "y = data.target\n",
    "\n",
    "ind = np.arange(X.shape[0])\n",
    "np.random.shuffle(ind)\n",
    "X = X[ind, :].copy()\n",
    "y = y[ind].copy()\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('xgb', XGBClassifier(n_estimators=3))])\n",
    "pipe.fit(X, y)\n",
    "\n",
    "save_onnx_filename = \"./models/pipeline_xgboost_classifier.onnx\"\n",
    "initial_type = [('input', FloatTensorType([None, 2]))]\n",
    "xgboost_to_onnx(pipe, xgb_mode=\"classifier\", save_onnx_filename=save_onnx_filename, initial_type=initial_type)\n",
    "\n",
    "# Compare the predictions\n",
    "print(\"\\n Predictions with XGBoost\")\n",
    "print(\"predict\", pipe.predict(X[:5]))\n",
    "print(\"predict_probabilities\", pipe.predict_proba(X[:1]))\n",
    "\n",
    "print(\"\\n Predictions with onnxruntime\")\n",
    "sess = ort.InferenceSession(save_onnx_filename)\n",
    "pred_onx = sess.run(None, {\"input\": X[:5].astype(np.float32)})\n",
    "print(\"predict\", pred_onx[0])\n",
    "print(\"predict_probabilities\", pred_onx[1][:1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion Pitfalls <a class=\"anchor\" id=\"1-2\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins>Regex tokenization (ONNX uses different regex engine)</ins>\n",
    "When converting a model to ONNX format, the model is represented in a graph format that describes the computations in the model. The ONNX runtime engine uses this graph to execute the model on different hardware platforms. However, the ONNX runtime engine only supports a subset of regular expressions, and some regex expressions can cause errors during runtime.\n",
    "\n",
    "Tokenization is a process of splitting a piece of text into individual tokens, such as words or phrases. Regex tokenization is a popular method of tokenization because it can handle complex patterns in the text. However, when converting a python-based Tokenizer (i.e. scikit-learn or pyspark), the ONNX runtime engine may not be able to handle some of the regex expressions. This can cause the model to fail during runtime, and the output may be different from the expected results.\n",
    "\n",
    "To avoid this problem, it is recommended to use a tokenization method that is supported by the ONNX runtime engine, for this please use the [ONNX Tokenizer](http://www.xavierdupre.fr/app/mlprodict/helpsphinx/onnxops/onnx_commicrosoft_Tokenizer.html#id1) by passing the regex expression to `tokenexp` attribute until it matches the expected output.\n",
    "\n",
    "\n",
    "\n",
    "#### <ins>Unsupported operators and float32/float64 verification</ins>\n",
    "\n",
    "The ONNX format does not support all the operators that are available in every deep learning framework. When converting a model, it is important to check whether all the operators used in the model are supported by ONNX.\n",
    "\n",
    "Even when the operators are available in the ONNX format, it can happen that some are not able to do float64. ONNX handles these cases by adding constants or casting nodes to float32, that we need to carefully modify in order to exactly replicate the accuracy of the original model.\n",
    "\n",
    "- Link to supported operators: https://github.com/onnx/onnx/blob/main/docs/Operators.md\n",
    "\n",
    "#### <ins>ColumnTransformer to separate inputs in scikit-learn</ins>\n",
    "\n",
    "When converting a scikit-learn model to ONNX format, it is possible to use a ColumnTransformer to separate the inputs into multiple columns and apply different transformations to each column. Please refer to [Remapping model inputs](#2-1) section for implementation details.\n",
    "\n",
    "\n",
    "#### <ins>Different input dimensions</ins>\n",
    "\n",
    "When defining a dynamic input shape for an ONNX model, you can use strings as dimension names for the batch dimension (the first dimension of the input shape). By convention, the two most common strings used for batch dimensions are 'batch_size' and 'N'. However, any string can be used as long as it is unique and consistent across all input tensors. We can use 'None' to represent an undefined batch size.\n",
    "\n",
    "**If the dimensions are different across inputs you need to define different strings to define the inputs.**\n",
    "\n",
    "    Example:\n",
    "\n",
    "```python\n",
    "from skl2onnx import convert_sklearn\n",
    "input_shape_1 = (None, 28, 28, 1)  # batch size is undefined\n",
    "input_shape_2 = (10, 32)  # batch size is 10\n",
    "\n",
    "initial_types = [('input_with_batchsize_defined', FloatTensorType(input_shape_1)),\n",
    "                ('input_with_undefined_batchsize', FloatTensorType(input_shape_2))]\n",
    "\n",
    "onnx_model = convert_sklearn(model, initial_types=initial_types)\n",
    "```\n",
    "\n",
    "#### <ins>Sparse to dense for CountVectorizer as input to XGBoost</ins>\n",
    "When using CountVectorizer to encode text data for use with XGBoost, the resulting feature matrix is typically sparse. When converting a sparse CountVectorizer feature matrix to ONNX format for use with XGBoost, it is important to ensure that the resulting ONNX model can handle sparse inputs efficiently.\n",
    "\n",
    "In the following example, we first fit a CountVectorizer on the training data to obtain a sparse feature matrix, X_train. We then convert this matrix to a dense format. The resulting dense feature matrix is then used as input to an ONNX model that represents an XGBoost classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from skl2onnx.common.data_types import StringTensorType\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from onnxmltools.convert import convert_xgboost\n",
    "\n",
    "from acslibrary.onnx_utils.conversion import sklearn_to_onnx\n",
    "\n",
    "# Load the 20 Newsgroups dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(newsgroups.data, newsgroups.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit a CountVectorizer on the training data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "initial_types=[(\"input\", StringTensorType([1,None]))]\n",
    "vector_onnx_model = sklearn_to_onnx(vectorizer, initial_types=initial_types, save_onnx_filename=\"./models/vector.onnx\")\n",
    "\n",
    "# Convert the sparse feature matrix to a dense format\n",
    "X_train_dense = X_train.todense()\n",
    "\n",
    "xgb=XGBClassifier()\n",
    "xgb.fit(X_train_dense,y_train)\n",
    "input = [onnx.helper.make_tensor_value_info('input', onnx.TensorProto.FLOAT, X_train_dense.shape)]\n",
    "xgb_onnx_model = convert_xgboost(xgb, initial_types=input)\n",
    "onnx.save(xgb_onnx_model, './models/xgb.onnx')\n",
    "\n",
    "combined_model = onnx.compose.merge_models(\n",
    "    vector_onnx_model, xgb_onnx_model,\n",
    "    io_map=[(\"variable\", \"input\")]\n",
    ")\n",
    "onnx.save(combined_model, './models/combined_model.onnx')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph modifications <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OnnxRuntime Optimization <a class=\"anchor\" id=\"2-0\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONNX Runtime defines the GraphOptimizationLevel enum to determine which of the aforementioned optimization levels will be enabled. Choosing a level enables the optimizations of that level, as well as the optimizations of all preceding levels. For example, enabling Extended optimizations, also enables Basic optimizations. The mapping of these levels to the enum is as follows:\n",
    "\n",
    "- GraphOptimizationLevel::ORT_DISABLE_ALL -> Disables all optimizations\n",
    "- GraphOptimizationLevel::ORT_ENABLE_BASIC -> Enables basic optimizations\n",
    "- GraphOptimizationLevel::ORT_ENABLE_EXTENDED -> Enables basic and extended optimizations\n",
    "- GraphOptimizationLevel::ORT_ENABLE_ALL -> Enables all available optimizations including layout optimizations\n",
    "\n",
    "Aditional Resources:\n",
    "* https://fs-eire.github.io/onnxruntime/docs/performance/graph-optimizations.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acslibrary.onnx_utils.graph_modifications import optimize_graph\n",
    "\n",
    "input_model_filename = \"./models/resampler.onnx\"\n",
    "optimized_model_filename = \"./models/resampler_optimized.onnx\"\n",
    "optimization_level = \"ORT_ENABLE_EXTENDED\"\n",
    "optimize_graph(input_model_filename, optimized_model_filename, optimization_level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remapping model inputs <a class=\"anchor\" id=\"2-1\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ColumnTransformer` is a scikit-learn transformer that applies different transformers to different columns of the input data. This can be useful when working with datasets that contain both numerical and categorical features, for example. The ColumnTransformer allows you to apply different transformations to each feature type, and then combine the results into a single output.\n",
    "\n",
    "The function `acslibrary.onnx_utils.graph_modifications.add_feature_concat` inserts the ColumnTransformer at the beginning of an already existing algorithm or pipeline. This way, when an model is converted to onnx, the inputs can be passed separated and the model compacts them into a single array.\n",
    "\n",
    "This function accepts multiple inputs:\n",
    "* Option 1: Pass the desired algorithm to the function, with or without algorithm argumentes\n",
    "* Option 2: Run the function over an existing sklearn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from acslibrary.onnx_utils.graph_modifications import add_feature_concat\n",
    "\n",
    "# Imagine that we have a dataframe with the following columns\n",
    "col_names = ['var1', 'var2', 'var3', 'var4']\n",
    "\n",
    "print (\"Option 1: pass the desired algorithm to the function\")\n",
    "model_op1 = add_feature_concat(col_names, algorithm=KNeighborsRegressor(), algorithm_name='knn')\n",
    "print(model_op1)\n",
    "\n",
    "# We can add the parameters that we want to the algorithm, and we can also not pass a name\n",
    "print (\"Option 1: pass the desired algorithm with parameters and without the name\")\n",
    "model_op1 = add_feature_concat(col_names, algorithm=KNeighborsRegressor(n_neighbors=10, algorithm='ball_tree', leaf_size=50))\n",
    "print(model_op1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also pass an already build pipeline and the column transformer will be added at the beginning\n",
    "print (\"Option2: Pass an already built pipeline \")\n",
    "model_op2 = Pipeline([('pca', PCA(n_components=2)), ('knn', KNeighborsRegressor())])\n",
    "print('Model before input feature separation')\n",
    "print(model_op2)\n",
    "\n",
    "add_feature_concat(col_names, pipeline=model_op2)\n",
    "print('Model after input feature separation')\n",
    "print(model_op2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming model outputs <a class=\"anchor\" id=\"2-2\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of existing ONNX model can be changed from standard [0, 1, 2, ...] to custom defined values: either a new list of int, strings or float, i.e [\"A\", \"B\", \"C\", ...].\n",
    "\n",
    "The mapping from existing output values to new output values is performed by modifying the graph. The existing label output node (or every output node) is removed and substituted it by a LabelEncoder node.\n",
    "\n",
    "`rename_onnx_outputs` allows deciding if removing:\n",
    "* all output nodes: \"all\"\n",
    "* specific output node: i.e. \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acslibrary.onnx_utils.graph_modifications import rename_onnx_outputs\n",
    "\n",
    "original_model_path = './models/GT_clustering.onnx'\n",
    "\n",
    "input_mapping = [0, 1, 2]\n",
    "mapping_examples = {\n",
    "    'int': [[1, 2, 3], int],\n",
    "    'float': [[1.0, 2.0, 3.0], float],\n",
    "    'str': [[\"A\", \"B\", \"C\"], str]\n",
    "}\n",
    "\n",
    "for new_output_type, output_mapping in mapping_examples.items():\n",
    "    new_model_path = f'./models/GT_clustering_new_output_{new_output_type}.onnx'\n",
    "\n",
    "    rename_onnx_outputs(original_model_path, input_mapping, output_mapping[0],\n",
    "                                new_model_path, output_node_to_replace=\"all\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging graphs <a class=\"anchor\" id=\"2-3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnx.utils\n",
    "from onnx.version_converter import convert_version\n",
    "\n",
    "# Load the two ONNX models\n",
    "model1 = onnx.load(model1_path)\n",
    "model2 = onnx.load(model2_path)\n",
    "\n",
    "# Check operator set versions of the two models\n",
    "print(\"Model 1 operator set version:\", model1.opset_import[0].version)\n",
    "print(\"Model 2 operator set version:\", model2.opset_import[0].version)\n",
    "\n",
    "# Set the target operator set version\n",
    "target_opset_version = 16\n",
    "\n",
    "# Update the first model to the target operator set version\n",
    "if model1.opset_import[0].version < target_opset_version:\n",
    "    model1 = convert_version(model1, target_version=target_opset_version)\n",
    "\n",
    "# Merge the two models\n",
    "merged_model = onnx.compose.merge_models(model1, model2,\n",
    "                                         io_map=[('model1_output','model2_input')])\n",
    "\n",
    "# Save the merged model\n",
    "merged_model_path = './models/merged_model.onnx'\n",
    "onnx.save(merged_model, merged_model_path)\n",
    "\n",
    "# Check operator set version of the merged model\n",
    "print(\"Merged model operator set version:\", merged_model.opset_import[0].version)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Data <a class=\"anchor\" id=\"3-2\"></a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KShape to ONNX <a class=\"anchor\" id=\"3-1\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*k-Shape* is a highly accurate and efficient unsupervised method for univariate and multivariate time-series clustering. \n",
    "\n",
    "The simplest way to use it in python is with the _tslearn.clustering.KShape_ library; however, the resulting model cannot be directly converted to onnx. KShape algorithm has been transformed to a pytorch model to be compatible with onnx transformation. Moreover, onnx conversion does not support float64 transformation in every node, therefore the resulting model needs to be modified in order to remove/add the corresponding nodes in float64 type.\n",
    "\n",
    "The pipeline to obtain a k-shape onnx model for inference follows:\n",
    "\n",
    "    1. Train original tslearn.clustering.KShape model.\n",
    "    2. Use tslearn k-shape cluster centers to fit Pytorch KShape (Aizon custom)\n",
    "    3. Convert Pytorch k-shape model to onnx\n",
    "    4. Modify model from step 3 to ensure all nodes support float64 types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tslearn.datasets import CachedDatasets\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from tslearn.clustering import KShape as tslearn_KShape\n",
    "\n",
    "import onnxruntime as ort\n",
    "from acslibrary.onnx_utils.kshape import kshape_to_onnx\n",
    "\n",
    "\n",
    "# Example data generation and split into train/test\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "X_train, y_train, X_test, y_test = CachedDatasets().load_dataset(\"Trace\")\n",
    "# Keep first 3 classes and 50 first time series\n",
    "X_train = X_train[y_train < 4]\n",
    "X_train = X_train[:50]\n",
    "np.random.shuffle(X_train)\n",
    "X_train=torch.from_numpy(X_train)\n",
    "\n",
    "X_train = TimeSeriesScalerMeanVariance().fit_transform(X_train)\n",
    "\n",
    "onnx_save_file = \"./models/kshape.onnx\"\n",
    "print(\"Exporting kshape model to onnx format\")\n",
    "kshape_to_onnx(X_train, num_clusters=3,seed=seed, save_onnx_filename=onnx_save_file)\n",
    "sess_kshape = ort.InferenceSession(onnx_save_file)\n",
    "onnx_pred = sess_kshape.run(None,{\"input_1\": X_test[:20],})\n",
    "print(f\"ONNX model saved in {onnx_save_file}\")\n",
    "\n",
    "print(\"Fitting training data to original tslearn kshape for comparison\")\n",
    "ks = tslearn_KShape(n_clusters=3, verbose=True, random_state=seed)\n",
    "tslearn_model = ks.fit(X_train)\n",
    "sklearn_pred = tslearn_model.predict(X_test[:20])\n",
    "\n",
    "## Compare\n",
    "print(f'\\nONNX results: \\n{onnx_pred[0]}')\n",
    "print(f'\\nTslearn results: \\n{sklearn_pred}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTW to ONNX <a class=\"anchor\" id=\"3-2\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTW is used as a distance metric in combination with a clustering algorhtm (i.e. k-means). It was converted to ONNX but it is still very slow - however the converted model is documented hereby for future use or development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import torch\n",
    "import onnx\n",
    "\n",
    "from acslibrary.onnx_utils.dtw import dtw_to_onnx\n",
    "from acslibrary.onnx_utils.graph_modifications import optimize_graph\n",
    "\n",
    "\n",
    "dummy_input_one = torch.Tensor([1, 2, 3, 10, 8, 5, 4, 1, 2])\n",
    "dummy_input_two = torch.Tensor([4, 5, 6, 2, 2])\n",
    "\n",
    "input_data = {\n",
    "        'input_data_1': dummy_input_one.numpy(),\n",
    "        'input_data_2': dummy_input_two.numpy(),\n",
    "    }\n",
    "\n",
    "filename = './models/dtw_torch.onnx'\n",
    "print(\"Exporting DTW model to onnx format\")\n",
    "dtw_to_onnx(filename)\n",
    "\n",
    "# optimize onnx graph\n",
    "filename_optimized = './models/dtw_optimized.onnx'\n",
    "optimize_graph(filename, optimized_model_filename=filename_optimized)\n",
    "so = ort.SessionOptions()\n",
    "sess_dtw = ort.InferenceSession(onnx.load(filename_optimized).SerializeToString(), so, providers=['CPUExecutionProvider'])\n",
    "onnx_pred = sess_dtw.run(None, input_data)\n",
    "\n",
    "print(f'\\nONNX results: \\n{onnx_pred[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling <a class=\"anchor\" id=\"3-2\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When loading time series data many times there exists redundancy and we want to compress the information across time for every batch.\n",
    "\n",
    "In order to reduce this redundancy, the function `acslibrary.ETL.scada_data.load_data` applies custom defined resampling, consisting in averaging the values of time series data within batches. In some cases, it is necessary to have additional information to describe how data has changed over time. This information can be extracted either with the difference of values between consecutive data points (diff) or the percentage change between the current and a prior data points (perc_change).\n",
    "\n",
    "The above mentioned function has been converted to ONNX format by defining both regular Resampler and Resampler with derivatives as Pytorch nn modules, to be merged before models when we want to resample input data.\n",
    "\n",
    "These onnx models can be trained and merged as follows:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Resampler onnx model (with or without derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from acslibrary.onnx_utils import resampling\n",
    "\n",
    "#Generate dummy input to feed model to export\n",
    "dummy_input = torch.randn(10,60).type(torch.float64)\n",
    "\n",
    "# Generate Resampler onnx model\n",
    "resampler_filename=\"./models/resampler.onnx\"\n",
    "resampling.resampler_to_onnx(dummy_input, n_chunks=9, save_onnx_filename=resampler_filename)\n",
    "\n",
    "# Generate Resampler onnx model with derivative\n",
    "resampler_derivative_filename=\"./models/resampler_with_derivative.onnx\"\n",
    "resampling.resampler_to_onnx(dummy_input, n_chunks=9, save_onnx_filename=resampler_derivative_filename, derivative=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Use Resampler onnx model instead of `load_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "import onnx\n",
    "import onnx.utils\n",
    "from onnx.version_converter import convert_version\n",
    "\n",
    "from acslibrary.onnx_utils.conversion import sklearn_to_onnx\n",
    "\n",
    "\n",
    "# Load Resampler ONNX model\n",
    "resampler_derivative_filename=\"./models/resampler_with_derivative.onnx\"\n",
    "resample_diff_model = onnx.load(resampler_derivative_filename)\n",
    "\n",
    "# Convert custom model to ONNX, i.e Kmeans \n",
    "X = np.arange(20).reshape(10, 2)\n",
    "kmeans_model = KMeans(n_clusters=2)\n",
    "kmeans_model.fit(X)\n",
    "kmean_onnx_filename = './models/k_means.onnx'\n",
    "sklearn_to_onnx(kmeans_model, initial_types=[('kmeans_input', FloatTensorType([1, 34]))], \n",
    "                save_onnx_filename=kmean_onnx_filename, target_opset=16)\n",
    "# Update the model to use the target operator set version\n",
    "k_means_onnx = onnx.load(kmean_onnx_filename)\n",
    "\n",
    "# Update the kmeans model to the target operator set version of the resampler model\n",
    "k_means_onnx = convert_version(k_means_onnx,target_version=16)\n",
    "\n",
    "#Generate combined model\n",
    "resample_k_means_model = onnx.compose.merge_models(resample_diff_model, k_means_onnx, \n",
    "                                                   io_map=[('resampler_output','kmeans_input')],\n",
    "                                              )\n",
    "\n",
    "onnx.checker.check_model(resample_k_means_model)\n",
    "onnx.save(resample_k_means_model, './models/res_diff_kmeans.onnx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX Prediction <a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "In order to predict the output of a given ONNX model, we need to create an onnxruntime inference session and then run it passing the onnx model and a given set of input values.\n",
    "\n",
    "To ease this process, one can use the onnx_predict method as in the following example. The function accepts either a loaded onnx model or the path of an existing onnx model. It returns the inference results in a dictionary with the corresponding output labels from the graph. If the format of the inputs is incorrect, it will display an error message indicating the correct shape or type of the data to be passed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from acslibrary.onnx_utils.conversion import onnx_predict\n",
    "\n",
    "incorrect_vals = np.array([[1,2]], dtype=np.float32)\n",
    "output = onnx_predict(incorrect_vals, onnx_model_path=\"./models/sklearn_tree_model.onnx\")\n",
    "print(\"Result\",output)\n",
    "\n",
    "print(\"____________\")\n",
    "corrected_vals = [np.array([[1,2]], dtype=np.float32)]\n",
    "output = onnx_predict(corrected_vals, onnx_model_path=\"./models/sklearn_tree_model.onnx\")\n",
    "print(\"Result\",output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP values <a class=\"anchor\" id=\"5\"></a>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Shapley Additive Explanations (SHAP)** values are a popular method for interpreting and explaining the predictions made by machine learning models. They provide insights into the contribution of each feature or variable towards a particular prediction. Shap values quantify the marginal contribution of each feature to the prediction when considering different possible combinations of features. By calculating Shap values, we can understand how individual features influence the model's output and gain valuable insights into the decision-making process.\n",
    "\n",
    "To further enhance the interpretability and applicability of machine learning models, the function `acslibrary.onnx_utils.shap.concat_with_shap` has been developed to seamlessly integrate SHAP values with an existing ONNX model. This function allows us to concatenate the SHAP value calculation module with the ONNX model, providing a streamlined approach to transforming SHAP values into the ONNX format.\n",
    "\n",
    "The function leverages a kernel explainer, which is a widely used method for estimating SHAP values. Kernel explainer approximates SHAP values by creating a reference dataset and sampling from it to evaluate the model's behavior across different feature combinations. By incorporating this explainer, we can effectively compute SHAP values for the given model and utilize them in conjunction with the ONNX representation.\n",
    "\n",
    "**Limitations:** the training and inference time required to run the model with shap increases exponentially with the number of input variables. Take this limitation into account when converting models to be used in the platform. To ensure inference time below 1 minute (platform limitation for inference time), the maximum amount of variables is 10."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Concatenate shap to an existing onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import onnx\n",
    "\n",
    "from acslibrary.onnx_utils.shap import concat_with_shap\n",
    "\n",
    "# Load training data used to fit base model\n",
    "kwargs = {'sep': '\\t', 'header': 'infer', 'encoding': 'utf-8', 'index_col': [0]}\n",
    "train_data_file = \"./models/training_data_X.csv\"\n",
    "X_train = pd.read_csv(train_data_file, index_col=0).values\n",
    "\n",
    "# Load base model in onnx format:\n",
    "# this model needs to have inputs concatenated into a single input\n",
    "# i.e. do not use \"feature_concat\" function\n",
    "base_model_path = \"./models/Frac1_pls.onnx\"\n",
    "onnx_base_model = onnx.load(base_model_path)\n",
    "\n",
    "# Define list with names for separate inputs of the final model\n",
    "input_names = ['input_33', 'input_47', 'input_6']\n",
    "# Define path to save final model\n",
    "save_onnx_filename = \"./models/Frac1_pls_with_shap.onnx\"\n",
    "\n",
    "# Create final model concatenating shapley values to base model\n",
    "shap_onxx_model = concat_with_shap(onnx_base_model, X_train, input_names, save_onnx_filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run inference to obtain shap values with the resulting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Run inference with the model with shap values\n",
    "sess_options = ort.SessionOptions()\n",
    "sess_options.log_severity_level = 3  # hide warning messages\n",
    "sess = ort.InferenceSession(shap_onxx_model.SerializeToString(),\n",
    "                                    sess_options=sess_options)\n",
    "\n",
    "inference_data = {\n",
    "    k.name: [[v]] for k, v in zip(sess.get_inputs(), np.array(X_train[2]))\n",
    "}\n",
    "results_onnx = sess.run(None, inference_data)\n",
    "\n",
    "results_dict = {}\n",
    "results_dict[\"prediction\"] = results_onnx[0][0].tolist()\n",
    "results_dict[\"shap_values\"] = results_onnx[1][-1].tolist()\n",
    "results_dict[\"expected_score\"] = float(results_onnx[2])\n",
    "print(results_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
